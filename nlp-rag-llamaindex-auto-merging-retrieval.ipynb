{"metadata":{"kernelspec":{"name":"python3","display_name":"Python 3","language":"python"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"}},"nbformat_minor":5,"nbformat":4,"cells":[{"cell_type":"markdown","source":"# Lesson 4: Auto-merging Retrieval\n\n![Auto-merging retrieval.png](https://github.com/YanSte/NLP-RAG-LLamaIndex-Auto-Merging-Retrieval/blob/main/schema1.png?raw=true)\n![Auto-merging retrieval.png](https://github.com/YanSte/NLP-RAG-LLamaIndex-Auto-Merging-Retrieval/blob/main/schema2.png?raw=true)","metadata":{}},{"cell_type":"code","source":"import warnings\nfrom kaggle_secrets import UserSecretsClient\nwarnings.filterwarnings('ignore')\n\nuser_secrets = UserSecretsClient()\nOPENAI_API_KEY = user_secrets.get_secret(\"OPEN_AI\")","metadata":{"execution":{"iopub.status.busy":"2024-03-13T19:43:59.352452Z","iopub.execute_input":"2024-03-13T19:43:59.352954Z","iopub.status.idle":"2024-03-13T19:43:59.530801Z","shell.execute_reply.started":"2024-03-13T19:43:59.352904Z","shell.execute_reply":"2024-03-13T19:43:59.529531Z"},"trusted":true},"execution_count":1,"outputs":[]},{"cell_type":"code","source":"%%capture\n!pip install trulens-eval\n!pip install llama-index\n!pip install llama-index-embeddings-huggingface\n!pip install torch sentence-transformers","metadata":{"execution":{"iopub.status.busy":"2024-03-13T19:44:01.588004Z","iopub.execute_input":"2024-03-13T19:44:01.588423Z","iopub.status.idle":"2024-03-13T19:45:24.494458Z","shell.execute_reply.started":"2024-03-13T19:44:01.588393Z","shell.execute_reply":"2024-03-13T19:45:24.492846Z"},"trusted":true},"execution_count":2,"outputs":[]},{"cell_type":"code","source":"import os\nimport openai\nopenai.api_key = OPENAI_API_KEY\nos.environ[\"OPENAI_API_KEY\"] = OPENAI_API_KEY","metadata":{"execution":{"iopub.status.busy":"2024-03-13T20:00:41.884678Z","iopub.execute_input":"2024-03-13T20:00:41.885108Z","iopub.status.idle":"2024-03-13T20:00:41.891402Z","shell.execute_reply.started":"2024-03-13T20:00:41.885078Z","shell.execute_reply":"2024-03-13T20:00:41.889905Z"},"trusted":true},"execution_count":42,"outputs":[]},{"cell_type":"code","source":"import os\n\n# Path to the directory where Kaggle stores the competition or dataset files\n# This path is just an example; you'll need to adjust it based on the specific competition or dataset\ninput_path = '/kaggle/input/'\n\nfor dirname, _, filenames in os.walk(input_path):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n","metadata":{"execution":{"iopub.status.busy":"2024-03-13T19:50:26.361898Z","iopub.execute_input":"2024-03-13T19:50:26.363060Z","iopub.status.idle":"2024-03-13T19:50:26.374918Z","shell.execute_reply.started":"2024-03-13T19:50:26.363015Z","shell.execute_reply":"2024-03-13T19:50:26.373848Z"},"trusted":true},"execution_count":7,"outputs":[{"name":"stdout","text":"/kaggle/input/generated_questions_11_15.text\n/kaggle/input/generated_questions_06_10.text\n/kaggle/input/generated_questions_21_24.text\n/kaggle/input/eBook-How-to-Build-a-Career-in-AI.pdf\n/kaggle/input/generated_questions_01_05.text\n/kaggle/input/generated_questions_16_20.text\n/kaggle/input/generated_questions.text\n","output_type":"stream"}]},{"cell_type":"code","source":"from llama_index.core import SimpleDirectoryReader\n\ndocuments = SimpleDirectoryReader(\n    input_files=[\"/kaggle/input/eBook-How-to-Build-a-Career-in-AI.pdf\"]\n).load_data()","metadata":{"tags":[],"execution":{"iopub.status.busy":"2024-03-13T19:50:35.284670Z","iopub.execute_input":"2024-03-13T19:50:35.285082Z","iopub.status.idle":"2024-03-13T19:50:37.174872Z","shell.execute_reply.started":"2024-03-13T19:50:35.285053Z","shell.execute_reply":"2024-03-13T19:50:37.173566Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"print(type(documents), \"\\n\")\nprint(len(documents), \"\\n\")\nprint(type(documents[0]))\nprint(documents[0])","metadata":{"tags":[],"execution":{"iopub.status.busy":"2024-03-13T19:50:46.159621Z","iopub.execute_input":"2024-03-13T19:50:46.160157Z","iopub.status.idle":"2024-03-13T19:50:46.168788Z","shell.execute_reply.started":"2024-03-13T19:50:46.160116Z","shell.execute_reply":"2024-03-13T19:50:46.167249Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stdout","text":"<class 'list'> \n\n41 \n\n<class 'llama_index.core.schema.Document'>\nDoc ID: 2c80ecae-ea75-440c-8c2f-859d2e6c74e3\nText: PAGE 1Founder, DeepLearning.AICollected Insights from Andrew Ng\nHow to  Build Your Career in AIA Simple Guide\n","output_type":"stream"}]},{"cell_type":"markdown","source":"## Auto-merging retrieval setup","metadata":{}},{"cell_type":"code","source":"from llama_index.core import Document\n\ndocument = Document(text=\"\\n\\n\".join([doc.text for doc in documents]))","metadata":{"tags":[],"execution":{"iopub.status.busy":"2024-03-13T19:50:52.916400Z","iopub.execute_input":"2024-03-13T19:50:52.917000Z","iopub.status.idle":"2024-03-13T19:50:52.924612Z","shell.execute_reply.started":"2024-03-13T19:50:52.916954Z","shell.execute_reply":"2024-03-13T19:50:52.923336Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"markdown","source":"Hierarchical node parser.\n\nSplits a document into a recursive hierarchy Nodes using a NodeParser.\n\nNOTE: this will return a hierarchy of nodes in a flat list, where there will be overlap between parent nodes (e.g. with a bigger chunk size), and child nodes per parent (e.g. with a smaller chunk size).\n\nFor instance, this may return a list of nodes like: - list of top-level nodes with chunk size 2048 - list of second-level nodes, where each node is a child of a top-level node,\n\nchunk size 512\n\nlist of third-level nodes, where each node is a child of a second-level node, chunk size 128","metadata":{}},{"cell_type":"code","source":"from llama_index.core.node_parser import HierarchicalNodeParser\n\n# create the hierarchical node parser w/ default settings\nnode_parser = HierarchicalNodeParser.from_defaults(\n    chunk_sizes=[2048, 512, 128]\n)","metadata":{"tags":[],"execution":{"iopub.status.busy":"2024-03-13T19:51:08.392088Z","iopub.execute_input":"2024-03-13T19:51:08.392534Z","iopub.status.idle":"2024-03-13T19:51:09.124071Z","shell.execute_reply.started":"2024-03-13T19:51:08.392505Z","shell.execute_reply":"2024-03-13T19:51:09.123110Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"code","source":"nodes = node_parser.get_nodes_from_documents([document])","metadata":{"tags":[],"execution":{"iopub.status.busy":"2024-03-13T19:51:11.392550Z","iopub.execute_input":"2024-03-13T19:51:11.393202Z","iopub.status.idle":"2024-03-13T19:51:11.634740Z","shell.execute_reply.started":"2024-03-13T19:51:11.393135Z","shell.execute_reply":"2024-03-13T19:51:11.633449Z"},"trusted":true},"execution_count":14,"outputs":[]},{"cell_type":"code","source":"from llama_index.core.node_parser import get_leaf_nodes\n\nleaf_nodes = get_leaf_nodes(nodes)\nprint(leaf_nodes[30].text)","metadata":{"tags":[],"execution":{"iopub.status.busy":"2024-03-13T19:51:19.180473Z","iopub.execute_input":"2024-03-13T19:51:19.180960Z","iopub.status.idle":"2024-03-13T19:51:19.189285Z","shell.execute_reply.started":"2024-03-13T19:51:19.180927Z","shell.execute_reply":"2024-03-13T19:51:19.187590Z"},"trusted":true},"execution_count":15,"outputs":[{"name":"stdout","text":"But this became less important as numerical linear algebra libraries matured.\nDeep learning is still an emerging technology, so when you train a neural network and the \noptimization algorithm struggles to converge, understanding the math behind gradient \ndescent, momentum, and the Adam  optimization algorithm will help you make better decisions. \nSimilarly, if your neural network does something funny — say, it makes bad predictions on \nimages of a certain resolution, but not others — understanding the math behind neural network \narchitectures puts you in a better position to figure out what to do.\nOf course, I also encourage learning driven by curiosity.\n","output_type":"stream"}]},{"cell_type":"code","source":"nodes_by_id = {node.node_id: node for node in nodes}\n\nparent_node = nodes_by_id[leaf_nodes[30].parent_node.node_id]\nprint(parent_node.text)","metadata":{"tags":[],"execution":{"iopub.status.busy":"2024-03-13T19:51:29.461090Z","iopub.execute_input":"2024-03-13T19:51:29.461567Z","iopub.status.idle":"2024-03-13T19:51:29.468730Z","shell.execute_reply.started":"2024-03-13T19:51:29.461529Z","shell.execute_reply":"2024-03-13T19:51:29.467484Z"},"trusted":true},"execution_count":16,"outputs":[{"name":"stdout","text":"PAGE 12Should You \nLearn Math to \nGet a Job in AI? CHAPTER 3\nLEARNING\n\nPAGE 13Should you Learn Math to Get a Job in AI? CHAPTER 3\nIs math a foundational skill for AI? It’s always nice to know more math! But there’s so much to \nlearn that, realistically, it’s necessary to prioritize. Here’s how you might go about strengthening \nyour math background.\nTo figure out what’s important to know, I find it useful to ask what you need to know to make \nthe decisions required for the work you want to do. At DeepLearning.AI, we frequently ask, \n“What does someone need to know to accomplish their goals?” The goal might be building a \nmachine learning model, architecting a system, or passing a job interview.\nUnderstanding the math behind algorithms you use is often helpful, since it enables you to \ndebug them. But the depth of knowledge that’s useful changes over time. As machine learning \ntechniques mature and become more reliable and turnkey, they require less debugging, and a \nshallower understanding of the math involved may be sufficient to make them work.\nFor instance, in an earlier era of machine learning, linear algebra libraries for solving linear \nsystems of equations (for linear regression) were immature. I had to understand how these \nlibraries worked so I could choose among different libraries and avoid numerical roundoff \npitfalls. But this became less important as numerical linear algebra libraries matured.\nDeep learning is still an emerging technology, so when you train a neural network and the \noptimization algorithm struggles to converge, understanding the math behind gradient \ndescent, momentum, and the Adam  optimization algorithm will help you make better decisions. \nSimilarly, if your neural network does something funny — say, it makes bad predictions on \nimages of a certain resolution, but not others — understanding the math behind neural network \narchitectures puts you in a better position to figure out what to do.\nOf course, I also encourage learning driven by curiosity. If something interests you, go ahead \nand learn it regardless of how useful it might turn out to be!  Maybe this will lead to a creative \nspark or technical breakthrough.How much math do you need to know to be a machine learning engineer?\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Building the index","metadata":{}},{"cell_type":"code","source":"from llama_index.llms.openai import OpenAI\n\nllm = OpenAI(model=\"gpt-3.5-turbo\", temperature=0.1)","metadata":{"tags":[],"execution":{"iopub.status.busy":"2024-03-13T19:52:08.528524Z","iopub.execute_input":"2024-03-13T19:52:08.529443Z","iopub.status.idle":"2024-03-13T19:52:08.548002Z","shell.execute_reply.started":"2024-03-13T19:52:08.529398Z","shell.execute_reply":"2024-03-13T19:52:08.546939Z"},"trusted":true},"execution_count":18,"outputs":[]},{"cell_type":"markdown","source":"The service context container is a utility container for LlamaIndex index and query classes. The container contains the following objects that are commonly used for configuring every index and query, such as the LLM, the PromptHelper (for configuring input size/chunk size), the BaseEmbedding (for configuring the embedding model), and more.\n","metadata":{}},{"cell_type":"code","source":"from llama_index.core import ServiceContext\n\nauto_merging_context = ServiceContext.from_defaults(\n    llm=llm,\n    embed_model=\"local:BAAI/bge-small-en-v1.5\",\n    node_parser=node_parser,\n)","metadata":{"tags":[],"execution":{"iopub.status.busy":"2024-03-13T19:52:14.573980Z","iopub.execute_input":"2024-03-13T19:52:14.574470Z","iopub.status.idle":"2024-03-13T19:52:20.671223Z","shell.execute_reply.started":"2024-03-13T19:52:14.574440Z","shell.execute_reply":"2024-03-13T19:52:20.670008Z"},"trusted":true},"execution_count":19,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/743 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c87a2741da434eff929a2c88420a22a7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/133M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"c1859f3d4df24ce8a3832f6bb723852d"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/366 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1ed4be8f88214ebaa1bdc623e63262e7"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"vocab.txt:   0%|          | 0.00/232k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"941bd3eb916f425cbb6dbd6211a949cb"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/711k [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"635485e170114f0093fe0b516598925a"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/125 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"635aa8b3098948b89851c1c6f1666867"}},"metadata":{}}]},{"cell_type":"markdown","source":"StorageContext\nLlamaIndex offers core abstractions around storage of Nodes, indices, and vectors. A key abstraction is the StorageContext - this contains the underlying BaseDocumentStore (for nodes), BaseIndexStore (for indices), and VectorStore (for vectors).\n\nThe Document/Node and index stores rely on a common KVStore abstraction, which is also detailed below.\n\nWe show the API references for the Storage Classes, loading indices from the Storage Context, and the Storage Context class itself below.","metadata":{}},{"cell_type":"markdown","source":"Vector Stores are a key component of retrieval-augmented generation (RAG) and so you will end up using them in nearly every application you make using LlamaIndex, either directly or indirectly.\n\nVector stores accept a list of Node objects and build an index from them","metadata":{}},{"cell_type":"code","source":"from llama_index.core import VectorStoreIndex, StorageContext\n\nstorage_context = StorageContext.from_defaults()\nstorage_context.docstore.add_documents(nodes)\n\nautomerging_index = VectorStoreIndex(\n    leaf_nodes, storage_context=storage_context, service_context=auto_merging_context\n)\n\nautomerging_index.storage_context.persist(persist_dir=\"./merging_index\")","metadata":{"tags":[],"execution":{"iopub.status.busy":"2024-03-13T19:55:07.151006Z","iopub.execute_input":"2024-03-13T19:55:07.151535Z","iopub.status.idle":"2024-03-13T19:55:14.316331Z","shell.execute_reply.started":"2024-03-13T19:55:07.151498Z","shell.execute_reply":"2024-03-13T19:55:14.315426Z"},"trusted":true},"execution_count":23,"outputs":[]},{"cell_type":"code","source":"# This block of code is optional to check\n# if an index file exist, then it will load it\n# if not, it will rebuild it\n\nimport os\nfrom llama_index.core import VectorStoreIndex, StorageContext, load_index_from_storage\nfrom llama_index.core import load_index_from_storage\n\nif not os.path.exists(\"./merging_index\"):\n    storage_context = StorageContext.from_defaults()\n    storage_context.docstore.add_documents(nodes)\n\n    automerging_index = VectorStoreIndex(\n            leaf_nodes,\n            storage_context=storage_context,\n            service_context=auto_merging_context\n        )\n\n    automerging_index.storage_context.persist(persist_dir=\"./merging_index\")\nelse:\n    automerging_index = load_index_from_storage(\n        StorageContext.from_defaults(persist_dir=\"./merging_index\"),\n        service_context=auto_merging_context\n    )\n","metadata":{"tags":[],"execution":{"iopub.status.busy":"2024-03-13T19:55:14.318390Z","iopub.execute_input":"2024-03-13T19:55:14.319102Z","iopub.status.idle":"2024-03-13T19:55:14.703494Z","shell.execute_reply.started":"2024-03-13T19:55:14.319063Z","shell.execute_reply":"2024-03-13T19:55:14.702498Z"},"trusted":true},"execution_count":24,"outputs":[]},{"cell_type":"markdown","source":"### Defining the retriever and running the query engine","metadata":{}},{"cell_type":"markdown","source":"AutoMergingRetriever, which looks at a set of leaf nodes and recursively “merges” subsets of leaf nodes that reference a parent node beyond a given threshold. This allows us to consolidate potentially disparate, smaller contexts into a larger context that might help synthesis.\n\nSentenceTransformerRerank\nUses the cross-encoders from the sentence-transformer package to re-order nodes, and returns the top N nodes.","metadata":{}},{"cell_type":"markdown","source":"RecursiveRetriever object to recursively retrieve/query nodes.","metadata":{}},{"cell_type":"code","source":"from llama_index.core.indices.postprocessor import SentenceTransformerRerank\nfrom llama_index.core.retrievers import AutoMergingRetriever\nfrom llama_index.core.query_engine import RetrieverQueryEngine\n\nautomerging_retriever = automerging_index.as_retriever(\n    similarity_top_k=12\n)\n\nretriever = AutoMergingRetriever(\n    automerging_retriever, \n    automerging_index.storage_context, \n    verbose=True\n)\n\nrerank = SentenceTransformerRerank(top_n=6, model=\"BAAI/bge-reranker-base\")\n\nauto_merging_engine = RetrieverQueryEngine.from_args(\n    automerging_retriever, node_postprocessors=[rerank]\n)","metadata":{"tags":[],"execution":{"iopub.status.busy":"2024-03-13T19:53:04.054565Z","iopub.execute_input":"2024-03-13T19:53:04.055267Z","iopub.status.idle":"2024-03-13T19:53:29.372622Z","shell.execute_reply.started":"2024-03-13T19:53:04.055223Z","shell.execute_reply":"2024-03-13T19:53:29.371418Z"},"trusted":true},"execution_count":22,"outputs":[{"output_type":"display_data","data":{"text/plain":"config.json:   0%|          | 0.00/799 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"a476df15948b4611813dbad5d16bd2a8"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"model.safetensors:   0%|          | 0.00/1.11G [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"1e2f798d49004b97a5742f07eec0c8a3"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer_config.json:   0%|          | 0.00/443 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2cff9489a09e4f3e93544e9609c76b63"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"sentencepiece.bpe.model:   0%|          | 0.00/5.07M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"3d6eb8f193114b82b29ecc216ea22f7c"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"tokenizer.json:   0%|          | 0.00/17.1M [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"98b53101fdff4c2c835fe932e5b76aa2"}},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"special_tokens_map.json:   0%|          | 0.00/279 [00:00<?, ?B/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"e44f771e43854caaabbc051c84b834ab"}},"metadata":{}}]},{"cell_type":"code","source":"auto_merging_response = auto_merging_engine.query(\n    \"What is the importance of networking in AI?\"\n)","metadata":{"tags":[],"execution":{"iopub.status.busy":"2024-03-13T19:56:54.950113Z","iopub.execute_input":"2024-03-13T19:56:54.950717Z","iopub.status.idle":"2024-03-13T19:57:00.133011Z","shell.execute_reply.started":"2024-03-13T19:56:54.950676Z","shell.execute_reply":"2024-03-13T19:57:00.131965Z"},"trusted":true},"execution_count":25,"outputs":[{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"24c7cba9f0104a598be14f2a2f010e69"}},"metadata":{}}]},{"cell_type":"code","source":"from llama_index.core.response.notebook_utils import display_response\n\ndisplay_response(auto_merging_response)","metadata":{"execution":{"iopub.status.busy":"2024-03-13T19:57:07.726519Z","iopub.execute_input":"2024-03-13T19:57:07.726925Z","iopub.status.idle":"2024-03-13T19:57:07.737051Z","shell.execute_reply.started":"2024-03-13T19:57:07.726895Z","shell.execute_reply":"2024-03-13T19:57:07.735522Z"},"trusted":true},"execution_count":27,"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.Markdown object>","text/markdown":"**`Final Response:`** Networking in AI is crucial as it allows individuals to build a strong professional community that can provide valuable information, support, and opportunities. By connecting with others in the field, individuals can receive help, advice, and referrals to potential employers. Additionally, networking can lead to collaborations, idea-sharing, and continuous learning, ultimately propelling individuals forward in their AI journey."},"metadata":{}}]},{"cell_type":"markdown","source":"## Putting it all Together","metadata":{}},{"cell_type":"code","source":"import os\n\nfrom llama_index.core import (\n    ServiceContext,\n    StorageContext,\n    VectorStoreIndex,\n    load_index_from_storage,\n)\nfrom llama_index.core.node_parser import HierarchicalNodeParser\nfrom llama_index.core.node_parser import get_leaf_nodes\nfrom llama_index.core import StorageContext, load_index_from_storage\nfrom llama_index.core.retrievers import AutoMergingRetriever\nfrom llama_index.core.indices.postprocessor import SentenceTransformerRerank\nfrom llama_index.core.query_engine import RetrieverQueryEngine\n\n\ndef build_automerging_index(\n    documents,\n    llm,\n    embed_model=\"local:BAAI/bge-small-en-v1.5\",\n    save_dir=\"merging_index\",\n    chunk_sizes=None,\n):\n    chunk_sizes = chunk_sizes or [2048, 512, 128]\n    node_parser = HierarchicalNodeParser.from_defaults(chunk_sizes=chunk_sizes)\n    nodes = node_parser.get_nodes_from_documents(documents)\n    leaf_nodes = get_leaf_nodes(nodes)\n    merging_context = ServiceContext.from_defaults(\n        llm=llm,\n        embed_model=embed_model,\n    )\n    storage_context = StorageContext.from_defaults()\n    storage_context.docstore.add_documents(nodes)\n\n    if not os.path.exists(save_dir):\n        automerging_index = VectorStoreIndex(\n            leaf_nodes, storage_context=storage_context, service_context=merging_context\n        )\n        automerging_index.storage_context.persist(persist_dir=save_dir)\n    else:\n        automerging_index = load_index_from_storage(\n            StorageContext.from_defaults(persist_dir=save_dir),\n            service_context=merging_context,\n        )\n    return automerging_index\n\n\ndef get_automerging_query_engine(\n    automerging_index,\n    similarity_top_k=12,\n    rerank_top_n=6,\n):\n    base_retriever = automerging_index.as_retriever(similarity_top_k=similarity_top_k)\n    retriever = AutoMergingRetriever(\n        base_retriever, automerging_index.storage_context, verbose=True\n    )\n    rerank = SentenceTransformerRerank(\n        top_n=rerank_top_n, model=\"BAAI/bge-reranker-base\"\n    )\n    auto_merging_engine = RetrieverQueryEngine.from_args(\n        retriever, node_postprocessors=[rerank]\n    )\n    return auto_merging_engine","metadata":{"execution":{"iopub.status.busy":"2024-03-13T19:57:22.136320Z","iopub.execute_input":"2024-03-13T19:57:22.136855Z","iopub.status.idle":"2024-03-13T19:57:22.149038Z","shell.execute_reply.started":"2024-03-13T19:57:22.136818Z","shell.execute_reply":"2024-03-13T19:57:22.147718Z"},"trusted":true},"execution_count":28,"outputs":[]},{"cell_type":"code","source":"from llama_index.llms.openai import OpenAI\n\nindex = build_automerging_index(\n    [document],\n    llm=OpenAI(model=\"gpt-3.5-turbo\", temperature=0.1),\n    save_dir=\"./merging_index\",\n)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-13T19:58:14.166476Z","iopub.execute_input":"2024-03-13T19:58:14.167147Z","iopub.status.idle":"2024-03-13T19:58:15.080678Z","shell.execute_reply.started":"2024-03-13T19:58:14.167109Z","shell.execute_reply":"2024-03-13T19:58:15.079640Z"},"trusted":true},"execution_count":29,"outputs":[]},{"cell_type":"code","source":"query_engine = get_automerging_query_engine(index, similarity_top_k=6)","metadata":{"execution":{"iopub.status.busy":"2024-03-13T19:58:18.642521Z","iopub.execute_input":"2024-03-13T19:58:18.642983Z","iopub.status.idle":"2024-03-13T19:58:21.424911Z","shell.execute_reply.started":"2024-03-13T19:58:18.642952Z","shell.execute_reply":"2024-03-13T19:58:21.423910Z"},"trusted":true},"execution_count":30,"outputs":[]},{"cell_type":"markdown","source":"## TruLens Evaluation","metadata":{}},{"cell_type":"code","source":"from trulens_eval import Tru\n\nTru().reset_database()","metadata":{"execution":{"iopub.status.busy":"2024-03-13T19:58:29.338792Z","iopub.execute_input":"2024-03-13T19:58:29.339316Z","iopub.status.idle":"2024-03-13T19:58:34.192971Z","shell.execute_reply.started":"2024-03-13T19:58:29.339277Z","shell.execute_reply":"2024-03-13T19:58:34.191886Z"},"trusted":true},"execution_count":31,"outputs":[{"name":"stderr","text":"[nltk_data] Downloading package stopwords to\n[nltk_data]     /opt/conda/lib/python3.10/site-\n[nltk_data]     packages/llama_index/legacy/_static/nltk_cache...\n[nltk_data]   Unzipping corpora/stopwords.zip.\n[nltk_data] Downloading package punkt to\n[nltk_data]     /opt/conda/lib/python3.10/site-\n[nltk_data]     packages/llama_index/legacy/_static/nltk_cache...\n[nltk_data]   Unzipping tokenizers/punkt.zip.\n","output_type":"stream"},{"name":"stdout","text":"🦑 Tru initialized with db url sqlite:///default.sqlite .\n🛑 Secret keys may be written to the database. See the `database_redact_keys` option of Tru` to prevent this.\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Two layers","metadata":{}},{"cell_type":"code","source":"auto_merging_index_0 = build_automerging_index(\n    documents,\n    llm=OpenAI(model=\"gpt-3.5-turbo\", temperature=0.1),\n    embed_model=\"local:BAAI/bge-small-en-v1.5\",\n    save_dir=\"merging_index_0\",\n    chunk_sizes=[2048,512],\n)","metadata":{"execution":{"iopub.status.busy":"2024-03-13T19:58:35.578986Z","iopub.execute_input":"2024-03-13T19:58:35.579463Z","iopub.status.idle":"2024-03-13T19:58:56.738389Z","shell.execute_reply.started":"2024-03-13T19:58:35.579426Z","shell.execute_reply":"2024-03-13T19:58:56.737177Z"},"trusted":true},"execution_count":32,"outputs":[]},{"cell_type":"code","source":"auto_merging_engine_0 = get_automerging_query_engine(\n    auto_merging_index_0,\n    similarity_top_k=12,\n    rerank_top_n=6,\n)","metadata":{"execution":{"iopub.status.busy":"2024-03-13T19:58:56.742392Z","iopub.execute_input":"2024-03-13T19:58:56.742756Z","iopub.status.idle":"2024-03-13T19:58:58.978384Z","shell.execute_reply.started":"2024-03-13T19:58:56.742727Z","shell.execute_reply":"2024-03-13T19:58:58.977074Z"},"trusted":true},"execution_count":33,"outputs":[]},{"cell_type":"code","source":"\n\nimport nest_asyncio\n\nnest_asyncio.apply()\ndef get_prebuilt_trulens_recorder(query_engine, app_id):\n    from trulens_eval import (\n            Feedback,\n            TruLlama,\n            OpenAI\n        )\n    from trulens_eval.feedback import Groundedness\n    import numpy as np\n\n    openai = OpenAI()\n\n    qa_relevance = (\n        Feedback(openai.relevance_with_cot_reasons, name=\"Answer Relevance\")\n        .on_input_output()\n    )\n\n    qs_relevance = (\n        Feedback(openai.relevance_with_cot_reasons, name = \"Context Relevance\")\n        .on_input()\n        .on(TruLlama.select_source_nodes().node.text)\n        .aggregate(np.mean)\n    )\n\n#     grounded = Groundedness(groundedness_provider=openai, summarize_provider=openai)\n    grounded = Groundedness(groundedness_provider=openai)\n\n    groundedness = (\n        Feedback(grounded.groundedness_measure_with_cot_reasons, name=\"Groundedness\")\n            .on(TruLlama.select_source_nodes().node.text)\n            .on_output()\n            .aggregate(grounded.grounded_statements_aggregator)\n    )\n\n    feedbacks = [qa_relevance, qs_relevance, groundedness]\n    tru_recorder = TruLlama(\n        query_engine,\n        app_id=app_id,\n        feedbacks=feedbacks\n    )\n    return tru_recorder","metadata":{"execution":{"iopub.status.busy":"2024-03-13T20:04:29.309004Z","iopub.execute_input":"2024-03-13T20:04:29.311057Z","iopub.status.idle":"2024-03-13T20:04:29.322632Z","shell.execute_reply.started":"2024-03-13T20:04:29.310999Z","shell.execute_reply":"2024-03-13T20:04:29.321582Z"},"trusted":true},"execution_count":58,"outputs":[]},{"cell_type":"code","source":"\ntru_recorder = get_prebuilt_trulens_recorder(\n    auto_merging_engine_0,\n    app_id ='app_0'\n)","metadata":{"execution":{"iopub.status.busy":"2024-03-13T20:01:54.374855Z","iopub.execute_input":"2024-03-13T20:01:54.375355Z","iopub.status.idle":"2024-03-13T20:01:54.792842Z","shell.execute_reply.started":"2024-03-13T20:01:54.375319Z","shell.execute_reply":"2024-03-13T20:01:54.791857Z"},"trusted":true},"execution_count":47,"outputs":[{"name":"stdout","text":"✅ In Answer Relevance, input prompt will be set to __record__.main_input or `Select.RecordInput` .\n✅ In Answer Relevance, input response will be set to __record__.main_output or `Select.RecordOutput` .\n✅ In Context Relevance, input prompt will be set to __record__.main_input or `Select.RecordInput` .\n✅ In Context Relevance, input response will be set to __record__.app.query.rets.source_nodes[:].node.text .\n✅ In Groundedness, input source will be set to __record__.app.query.rets.source_nodes[:].node.text .\n✅ In Groundedness, input statement will be set to __record__.main_output or `Select.RecordOutput` .\n","output_type":"stream"}]},{"cell_type":"code","source":"eval_questions = []\nwith open('/kaggle/input/generated_questions.text', 'r') as file:\n    for line in file:\n        # Remove newline character and convert to integer\n        item = line.strip()\n        eval_questions.append(item)","metadata":{"execution":{"iopub.status.busy":"2024-03-13T20:02:33.653814Z","iopub.execute_input":"2024-03-13T20:02:33.654342Z","iopub.status.idle":"2024-03-13T20:02:33.677420Z","shell.execute_reply.started":"2024-03-13T20:02:33.654307Z","shell.execute_reply":"2024-03-13T20:02:33.675581Z"},"trusted":true},"execution_count":49,"outputs":[]},{"cell_type":"code","source":"def run_evals(eval_questions, tru_recorder, query_engine):\n    for question in eval_questions:\n        with tru_recorder as recording:\n            response = query_engine.query(question)","metadata":{"execution":{"iopub.status.busy":"2024-03-13T20:02:35.417170Z","iopub.execute_input":"2024-03-13T20:02:35.418285Z","iopub.status.idle":"2024-03-13T20:02:35.425222Z","shell.execute_reply.started":"2024-03-13T20:02:35.418240Z","shell.execute_reply":"2024-03-13T20:02:35.423936Z"},"trusted":true},"execution_count":50,"outputs":[]},{"cell_type":"code","source":"run_evals(eval_questions, tru_recorder, auto_merging_engine_0)","metadata":{"execution":{"iopub.status.busy":"2024-03-13T20:02:36.914587Z","iopub.execute_input":"2024-03-13T20:02:36.915033Z","iopub.status.idle":"2024-03-13T20:02:59.324907Z","shell.execute_reply.started":"2024-03-13T20:02:36.915002Z","shell.execute_reply":"2024-03-13T20:02:59.298503Z"},"trusted":true},"execution_count":51,"outputs":[{"name":"stdout","text":"> Merging 2 nodes into parent node.\n> Parent node id: 9bb609a1-56ef-4f82-93de-7cc74cc92157.\n> Parent node text: PAGE 20Working on projects requires making tough choices about what to build and how to go \nabout...\n\n> Merging 1 nodes into parent node.\n> Parent node id: ff30b115-8f83-4f13-af4f-affbfa082461.\n> Parent node text: PAGE 7These phases apply in a wide \nrange of professions, but AI \ninvolves unique elements.\nFor e...\n\n> Merging 1 nodes into parent node.\n> Parent node id: c75a2017-6fd6-4373-b932-c2ba11e1ed4d.\n> Parent node text: PAGE 18It goes without saying that we should only work on projects that are responsible, ethical,...\n\n> Merging 1 nodes into parent node.\n> Parent node id: 19961eed-7a15-431f-92e0-a7c5f1265212.\n> Parent node text: PAGE 22Over the course of a career, you’re likely to work on projects in succession, each growing...\n\n> Merging 1 nodes into parent node.\n> Parent node id: 5932e3f9-7011-4523-bdda-48f26928d659.\n> Parent node text: PAGE 15One of the most important skills of an AI architect is the ability to identify ideas that ...\n\n> Merging 1 nodes into parent node.\n> Parent node id: 16161a75-1322-4e67-8159-8e54369f08ff.\n> Parent node text: PAGE 23Each project is only one step on a longer journey, hopefully one that has a positive impac...\n\n> Merging 1 nodes into parent node.\n> Parent node id: 7fdb2c2e-14b3-4bc6-b939-6b2915c3e9f3.\n> Parent node text: PAGE 16Determine milestones. Once you’ve deemed a project sufficiently \nvaluable, the next step i...\n\n> Merging 1 nodes into parent node.\n> Parent node id: 329a1cfa-5f32-44d1-a84b-8e1d8cacf0d4.\n> Parent node text: PAGE 29If you’re preparing to switch roles (say, taking a job as a machine learning engineer for ...\n\n> Merging 1 nodes into parent node.\n> Parent node id: 5431981e-3d89-4912-8838-0ee52706e392.\n> Parent node text: PAGE 3Table of \nContentsIntroduction: Coding AI is the New Literacy.\nChapter 1: Three Steps to Ca...\n\n> Merging 1 nodes into parent node.\n> Parent node id: c2175b09-b933-4666-adcd-4eb2522b92c1.\n> Parent node text: PAGE 27There’s a lot we don’t know about the future: When will we cure Alzheimer’s disease? Who w...\n\n> Merging 1 nodes into parent node.\n> Parent node id: cc425c9c-1dd5-467e-939c-a1c54c4e4d2e.\n> Parent node text: PAGE 6The rapid rise of AI has led to a rapid rise in AI jobs, and many people are building excit...\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"10e882e1809f4c2db1a121f0b9cede33"}},"metadata":{}}]},{"cell_type":"code","source":"from trulens_eval import Tru\n\nTru().get_leaderboard(app_ids=[])","metadata":{"execution":{"iopub.status.busy":"2024-03-13T20:02:59.344867Z","iopub.execute_input":"2024-03-13T20:02:59.345572Z","iopub.status.idle":"2024-03-13T20:02:59.425865Z","shell.execute_reply.started":"2024-03-13T20:02:59.345536Z","shell.execute_reply":"2024-03-13T20:02:59.424540Z"},"trusted":true},"execution_count":52,"outputs":[{"execution_count":52,"output_type":"execute_result","data":{"text/plain":"        latency  total_cost\napp_id                     \napp_0      20.0    0.004565","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>latency</th>\n      <th>total_cost</th>\n    </tr>\n    <tr>\n      <th>app_id</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>app_0</th>\n      <td>20.0</td>\n      <td>0.004565</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"Tru().run_dashboard()","metadata":{"execution":{"iopub.status.busy":"2024-03-13T20:02:59.428617Z","iopub.execute_input":"2024-03-13T20:02:59.429249Z","iopub.status.idle":"2024-03-13T20:03:00.845996Z","shell.execute_reply.started":"2024-03-13T20:02:59.429213Z","shell.execute_reply":"2024-03-13T20:03:00.844865Z"},"trusted":true},"execution_count":53,"outputs":[{"name":"stdout","text":"Starting dashboard ...\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Accordion(children=(VBox(children=(VBox(children=(Label(value='STDOUT'), Output())), VBox(children=(Label(valu…","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"b38c3cef2bfe4c929442219d9264ae62"}},"metadata":{}},{"name":"stdout","text":"Dashboard started at http://172.19.2.2:8501 .\n","output_type":"stream"},{"execution_count":53,"output_type":"execute_result","data":{"text/plain":"<Popen: returncode: None args: ['streamlit', 'run', '--server.headless=True'...>"},"metadata":{}}]},{"cell_type":"markdown","source":"### Three layers","metadata":{}},{"cell_type":"code","source":"from llama_index.llms.openai import OpenAI\nauto_merging_index_1 = build_automerging_index(\n    documents,\n    llm=OpenAI(model=\"gpt-3.5-turbo\", temperature=0.1),\n    embed_model=\"local:BAAI/bge-small-en-v1.5\",\n    save_dir=\"merging_index_1\",\n    chunk_sizes=[2048,512,128],\n)","metadata":{"execution":{"iopub.status.busy":"2024-03-13T20:05:47.784821Z","iopub.execute_input":"2024-03-13T20:05:47.785342Z","iopub.status.idle":"2024-03-13T20:05:48.922634Z","shell.execute_reply.started":"2024-03-13T20:05:47.785302Z","shell.execute_reply":"2024-03-13T20:05:48.921423Z"},"trusted":true},"execution_count":65,"outputs":[]},{"cell_type":"code","source":"auto_merging_engine_1 = get_automerging_query_engine(\n    auto_merging_index_1,\n    similarity_top_k=12,\n    rerank_top_n=6,\n)\n","metadata":{"execution":{"iopub.status.busy":"2024-03-13T20:05:48.924872Z","iopub.execute_input":"2024-03-13T20:05:48.925271Z","iopub.status.idle":"2024-03-13T20:05:51.858941Z","shell.execute_reply.started":"2024-03-13T20:05:48.925237Z","shell.execute_reply":"2024-03-13T20:05:51.857720Z"},"trusted":true},"execution_count":66,"outputs":[]},{"cell_type":"code","source":"tru_recorder = get_prebuilt_trulens_recorder(\n    auto_merging_engine_1,\n    app_id ='app_1'\n)","metadata":{"execution":{"iopub.status.busy":"2024-03-13T20:05:51.860725Z","iopub.execute_input":"2024-03-13T20:05:51.861075Z","iopub.status.idle":"2024-03-13T20:05:52.286778Z","shell.execute_reply.started":"2024-03-13T20:05:51.861045Z","shell.execute_reply":"2024-03-13T20:05:52.285679Z"},"trusted":true},"execution_count":67,"outputs":[{"name":"stdout","text":"✅ In Answer Relevance, input prompt will be set to __record__.main_input or `Select.RecordInput` .\n✅ In Answer Relevance, input response will be set to __record__.main_output or `Select.RecordOutput` .\n✅ In Context Relevance, input prompt will be set to __record__.main_input or `Select.RecordInput` .\n✅ In Context Relevance, input response will be set to __record__.app.query.rets.source_nodes[:].node.text .\n✅ In Groundedness, input source will be set to __record__.app.query.rets.source_nodes[:].node.text .\n✅ In Groundedness, input statement will be set to __record__.main_output or `Select.RecordOutput` .\n","output_type":"stream"}]},{"cell_type":"code","source":"run_evals(eval_questions, tru_recorder, auto_merging_engine_1)","metadata":{"execution":{"iopub.status.busy":"2024-03-13T20:05:53.490662Z","iopub.execute_input":"2024-03-13T20:05:53.491292Z","iopub.status.idle":"2024-03-13T20:06:10.044517Z","shell.execute_reply.started":"2024-03-13T20:05:53.491239Z","shell.execute_reply":"2024-03-13T20:06:10.023430Z"},"trusted":true},"execution_count":68,"outputs":[{"name":"stdout","text":"> Merging 4 nodes into parent node.\n> Parent node id: 1ae10ec1-bb7b-4a1a-aba8-095210267fb1.\n> Parent node text: PAGE 20Working on projects requires making tough choices about what to build and how to go \nabout...\n\n> Merging 2 nodes into parent node.\n> Parent node id: 4e335593-33ae-4457-8d58-eb824e639426.\n> Parent node text: But when committing to a direction means making a costly investment or entering a one-\nway door  ...\n\n> Merging 2 nodes into parent node.\n> Parent node id: 0ab50442-39ef-4244-ba59-c76dfe82e5ea.\n> Parent node text: PAGE 20Working on projects requires making tough choices about what to build and how to go \nabout...\n\n","output_type":"stream"},{"output_type":"display_data","data":{"text/plain":"Batches:   0%|          | 0/1 [00:00<?, ?it/s]","application/vnd.jupyter.widget-view+json":{"version_major":2,"version_minor":0,"model_id":"2a2836a96e66412c865bc0e0045ca010"}},"metadata":{}}]},{"cell_type":"code","source":"from trulens_eval import Tru\n\nTru().get_leaderboard(app_ids=[])","metadata":{"execution":{"iopub.status.busy":"2024-03-13T20:06:10.068312Z","iopub.execute_input":"2024-03-13T20:06:10.068748Z","iopub.status.idle":"2024-03-13T20:06:10.145202Z","shell.execute_reply.started":"2024-03-13T20:06:10.068716Z","shell.execute_reply":"2024-03-13T20:06:10.141413Z"},"trusted":true},"execution_count":69,"outputs":[{"execution_count":69,"output_type":"execute_result","data":{"text/plain":"        Context Relevance  Groundedness  Answer Relevance  latency  total_cost\napp_id                                                                        \napp_1            0.333333      0.842857               0.9     16.0    0.002297\napp_0            0.200000      0.885714               0.9     20.0    0.004565","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>Context Relevance</th>\n      <th>Groundedness</th>\n      <th>Answer Relevance</th>\n      <th>latency</th>\n      <th>total_cost</th>\n    </tr>\n    <tr>\n      <th>app_id</th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>app_1</th>\n      <td>0.333333</td>\n      <td>0.842857</td>\n      <td>0.9</td>\n      <td>16.0</td>\n      <td>0.002297</td>\n    </tr>\n    <tr>\n      <th>app_0</th>\n      <td>0.200000</td>\n      <td>0.885714</td>\n      <td>0.9</td>\n      <td>20.0</td>\n      <td>0.004565</td>\n    </tr>\n  </tbody>\n</table>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"Tru().run_dashboard()","metadata":{"execution":{"iopub.status.busy":"2024-03-13T20:04:51.695039Z","iopub.execute_input":"2024-03-13T20:04:51.695394Z","iopub.status.idle":"2024-03-13T20:04:51.705884Z","shell.execute_reply.started":"2024-03-13T20:04:51.695365Z","shell.execute_reply":"2024-03-13T20:04:51.704674Z"},"trusted":true},"execution_count":62,"outputs":[{"name":"stdout","text":"Starting dashboard ...\nConfig file already exists. Skipping writing process.\nCredentials file already exists. Skipping writing process.\nDashboard already running at path:   Network URL: http://172.19.2.2:8501\n\n","output_type":"stream"},{"execution_count":62,"output_type":"execute_result","data":{"text/plain":"<Popen: returncode: None args: ['streamlit', 'run', '--server.headless=True'...>"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}